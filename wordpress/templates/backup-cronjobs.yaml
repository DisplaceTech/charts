{{- if .Values.backups.enabled }}

{{- if .Values.backups.uploads.schedule }}
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{ include "wordpress.fullname" . }}-uploads-backup
  labels:
    {{- include "wordpress.labels" . | nindent 4 }}
    app.kubernetes.io/component: backup
spec:
  schedule: {{ .Values.backups.uploads.schedule | quote }}
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
            fsGroup: 1000
          containers:
          - name: uploads-backup
            image: alpine:latest
            command:
            - /bin/sh
            - -c
            - |
              set -e
              
              # Check if backup secrets exist
              if [ -z "$S3_ENDPOINT" ] || [ -z "$S3_ACCESS_KEY" ] || [ -z "$S3_SECRET_KEY" ] || [ -z "$S3_BUCKET" ]; then
                echo "Backup secrets not configured, aborting backup"
                exit 0
              fi
              
              # Install required tools
              apk add --no-cache rsync aws-cli
              
              # Create backup directory
              mkdir -p /backup
              
              # Create timestamp
              TIMESTAMP=$(date +%Y%m%d_%H%M%S)
              BACKUP_FILE="uploads_backup_${TIMESTAMP}.tar.gz"
              
              # Create backup archive
              echo "Creating uploads backup..."
              tar -czf "/backup/${BACKUP_FILE}" -C /uploads .
              
              # Upload to S3
              echo "Uploading to S3..."
              aws s3 cp "/backup/${BACKUP_FILE}" "s3://${S3_BUCKET}/uploads/${BACKUP_FILE}" \
                --endpoint-url "${S3_ENDPOINT}" \
                --region "${S3_REGION:-us-east-1}"
              
              # Clean up old backups (keep for retention days)
              echo "Cleaning up old backups..."
              RETENTION_DAYS={{ .Values.backups.uploads.retention }}
              aws s3 ls "s3://${S3_BUCKET}/uploads/" \
                --endpoint-url "${S3_ENDPOINT}" \
                --region "${S3_REGION:-us-east-1}" | \
                awk '{print $4}' | \
                grep "uploads_backup_" | \
                sort | \
                head -n -${RETENTION_DAYS} | \
                while read file; do
                  aws s3 rm "s3://${S3_BUCKET}/uploads/${file}" \
                    --endpoint-url "${S3_ENDPOINT}" \
                    --region "${S3_REGION:-us-east-1}"
                done
              
              echo "Uploads backup completed successfully"
            env:
            - name: S3_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-endpoint
            - name: S3_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-access-key
            - name: S3_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-secret-key
            - name: S3_BUCKET
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-bucket
            - name: S3_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-region
            resources:
              {{- toYaml .Values.backups.uploads.resources | nindent 14 }}
            volumeMounts:
            - name: uploads
              mountPath: /uploads
            - name: backup-temp
              mountPath: /backup
          volumes:
          - name: uploads
            persistentVolumeClaim:
              claimName: {{ include "wordpress.fullname" . }}-uploads
          - name: backup-temp
            emptyDir: {}
{{- end }}

{{- if .Values.backups.database.schedule }}
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{ include "wordpress.fullname" . }}-database-backup
  labels:
    {{- include "wordpress.labels" . | nindent 4 }}
    app.kubernetes.io/component: backup
spec:
  schedule: {{ .Values.backups.database.schedule | quote }}
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          securityContext:
            runAsUser: 999
            runAsGroup: 999
            fsGroup: 999
          containers:
          - name: database-backup
            image: mysql:8.0
            command:
            - /bin/sh
            - -c
            - |
              set -e
              
              # Check if backup secrets exist
              if [ -z "$S3_ENDPOINT" ] || [ -z "$S3_ACCESS_KEY" ] || [ -z "$S3_SECRET_KEY" ] || [ -z "$S3_BUCKET" ]; then
                echo "Backup secrets not configured, aborting backup"
                exit 0
              fi
              
              # Install required tools
              apt-get update && apt-get install -y awscli && rm -rf /var/lib/apt/lists/*
              
              # Create backup directory
              mkdir -p /backup
              
              # Create timestamp
              TIMESTAMP=$(date +%Y%m%d_%H%M%S)
              BACKUP_FILE="database_backup_${TIMESTAMP}.sql.gz"
              
              # Create database backup
              echo "Creating database backup..."
              mysqldump \
                -h "${DB_HOST}" \
                -u "${DB_USER}" \
                -p"${DB_PASSWORD}" \
                --single-transaction \
                --routines \
                --triggers \
                "${DB_NAME}" | gzip > "/backup/${BACKUP_FILE}"
              
              # Upload to S3
              echo "Uploading to S3..."
              aws s3 cp "/backup/${BACKUP_FILE}" "s3://${S3_BUCKET}/database/${BACKUP_FILE}" \
                --endpoint-url "${S3_ENDPOINT}" \
                --region "${S3_REGION:-us-east-1}"
              
              # Clean up old backups (keep for retention days)
              echo "Cleaning up old backups..."
              RETENTION_DAYS={{ .Values.backups.database.retention }}
              aws s3 ls "s3://${S3_BUCKET}/database/" \
                --endpoint-url "${S3_ENDPOINT}" \
                --region "${S3_REGION:-us-east-1}" | \
                awk '{print $4}' | \
                grep "database_backup_" | \
                sort | \
                head -n -${RETENTION_DAYS} | \
                while read file; do
                  aws s3 rm "s3://${S3_BUCKET}/database/${file}" \
                    --endpoint-url "${S3_ENDPOINT}" \
                    --region "${S3_REGION:-us-east-1}"
                done
              
              echo "Database backup completed successfully"
            env:
            - name: DB_HOST
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.wordpress.name }}
                  key: db-host
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.wordpress.name }}
                  key: db-user
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.wordpress.name }}
                  key: db-password
            - name: DB_NAME
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.wordpress.name }}
                  key: db-name
            - name: S3_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-endpoint
            - name: S3_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-access-key
            - name: S3_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-secret-key
            - name: S3_BUCKET
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-bucket
            - name: S3_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.secrets.backup.name }}
                  key: s3-region
            resources:
              {{- toYaml .Values.backups.database.resources | nindent 14 }}
            volumeMounts:
            - name: backup-temp
              mountPath: /backup
          volumes:
          - name: backup-temp
            emptyDir: {}
{{- end }}

{{- end }} 